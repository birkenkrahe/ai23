{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "a6fc0c16-84ae-5e0f-8de4-d4f8ff56a115",
        "openai_ephemeral_user_id": "bb79a5f5-c00e-555e-b647-f15f56b4ef8d",
        "openai_subdivision1_iso_code": "US-AR"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "05349181-f066-4275-b2f2-f2e850cbec21",
      "cell_type": "markdown",
      "source": "# Decision Tree in Python from scratch",
      "metadata": {
        "noteable": {
          "cell_type": "markdown",
          "cell_hidden": false
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        }
      }
    },
    {
      "id": "66f8dd88-e6c8-45f4-b1a9-3d3000856d12",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "ad984a30-6394-4c6e-a425-cc4b24ea5a46",
          "cell_hidden": false
        },
        "ExecuteTime": {
          "end_time": "2023-10-10T17:01:57.518566+00:00",
          "start_time": "2023-10-10T17:01:57.355489+00:00"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        }
      },
      "execution_count": null,
      "source": "# Training data\ntraining_data = [\n    ['Red', 10, 'Apple'],\n    ['Purple', 1, 'Grape'],\n    ['Yellow', 8, 'Lemon'],\n    ['Red', 9, 'Apple'],\n    ['Purple', 1.5, 'Grape']\n]\n\ndef gini_impurity(rows):\n    \"\"\"Calculate the Gini Impurity for a list of rows.\"\"\"\n    counts = {}\n    for row in rows:\n        label = row[-1]\n        if label not in counts:\n            counts[label] = 0\n        counts[label] += 1\n    impurity = 1\n    total = len(rows)\n    for label in counts:\n        prob_of_label = counts[label] / total\n        impurity -= prob_of_label**2\n    return impurity\n\n# Test the Gini Impurity function\ngini_impurity(training_data)",
      "outputs": []
    },
    {
      "id": "936bdc78-1cf8-4212-8b53-52e43da3eb87",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "06af2676-6cbd-44cb-ad93-65ac90575ade",
          "cell_hidden": false
        },
        "ExecuteTime": {
          "end_time": "2023-10-10T17:03:19.673678+00:00",
          "start_time": "2023-10-10T17:03:19.513526+00:00"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        }
      },
      "execution_count": null,
      "source": "def split(rows, feature, value):\n    \"\"\"Split the dataset based on a feature and value.\"\"\"\n    true_rows = [row for row in rows if isinstance(value, str) and row[feature] == value or row[feature] >= value]\n    false_rows = [row for row in rows if isinstance(value, str) and row[feature] != value or row[feature] < value]\n    return true_rows, false_rows\n\ndef find_best_split(rows):\n    \"\"\"Find the best feature and value to split on.\"\"\"\n    best_gini = float('inf')\n    best_feature = None\n    best_value = None\n    n_features = len(rows[0]) - 1\n\n    for feature in range(n_features):\n        values = set([row[feature] for row in rows])\n        for value in values:\n            true_rows, false_rows = split(rows, feature, value)\n            if len(true_rows) == 0 or len(false_rows) == 0:\n                continue\n            weight_true = len(true_rows) / len(rows)\n            weight_false = len(false_rows) / len(rows)\n            gini = weight_true * gini_impurity(true_rows) + weight_false * gini_impurity(false_rows)\n            if gini < best_gini:\n                best_gini = gini\n                best_feature = feature\n                best_value = value\n\n    return best_feature, best_value\n\n# Test the find_best_split function\nfind_best_split(training_data)",
      "outputs": []
    },
    {
      "id": "13a8fbe1-c7d3-4fb9-b750-1e6b11f9e723",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "e2eb8fb8-e553-423c-b723-589d1ccc06b8",
          "cell_hidden": false
        },
        "ExecuteTime": {
          "end_time": "2023-10-10T17:04:29.808802+00:00",
          "start_time": "2023-10-10T17:04:29.647561+00:00"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        }
      },
      "execution_count": null,
      "source": "class DecisionNode:\n    def __init__(self, feature=None, value=None, true_branch=None, false_branch=None, prediction=None):\n        self.feature = feature\n        self.value = value\n        self.true_branch = true_branch\n        self.false_branch = false_branch\n        self.prediction = prediction\n\ndef build_tree(rows):\n    # Find the best feature and value to split on\n    feature, value = find_best_split(rows)\n\n    # If we couldn't find a split, this is a leaf node\n    if feature is None:\n        label_counts = {}\n        for row in rows:\n            label = row[-1]\n            if label not in label_counts:\n                label_counts[label] = 0\n            label_counts[label] += 1\n        prediction = max(label_counts, key=label_counts.get)\n        return DecisionNode(prediction=prediction)\n\n    # If we found a split, create the true and false branches\n    true_rows, false_rows = split(rows, feature, value)\n    true_branch = build_tree(true_rows)\n    false_branch = build_tree(false_rows)\n\n    return DecisionNode(feature, value, true_branch, false_branch)\n\n# Build the decision tree\ntree = build_tree(training_data)\ntree",
      "outputs": []
    },
    {
      "id": "b474ac9f-8d98-4b3b-b732-0db04a0e77ec",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "95b67d00-ede8-440c-970c-406871309a3d",
          "cell_hidden": false
        },
        "ExecuteTime": {
          "end_time": "2023-10-10T17:05:43.409978+00:00",
          "start_time": "2023-10-10T17:05:43.250831+00:00"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        }
      },
      "execution_count": null,
      "source": "def predict(node, row):\n    \"\"\"Predict the label for a row using the decision tree.\"\"\"\n    # If this is a leaf node, return the prediction\n    if node.prediction is not None:\n        return node.prediction\n\n    # Decide whether to follow the true branch or the false branch\n    if isinstance(node.value, str):\n        if row[node.feature] == node.value:\n            return predict(node.true_branch, row)\n        else:\n            return predict(node.false_branch, row)\n    else:\n        if row[node.feature] >= node.value:\n            return predict(node.true_branch, row)\n        else:\n            return predict(node.false_branch, row)\n\n# Test the prediction function on a new data point\nnew_data_point = ['Red', 7]\nprediction = predict(tree, new_data_point)\nprediction",
      "outputs": []
    },
    {
      "id": "1e07d2b9-b296-4bfc-bf2a-ed7461947c26",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "e36ea1f8-9e15-40f9-82b7-6912e49eef56",
          "cell_hidden": false
        },
        "ExecuteTime": {
          "end_time": "2023-10-10T17:07:33.390031+00:00",
          "start_time": "2023-10-10T17:07:33.232064+00:00"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        }
      },
      "execution_count": null,
      "source": "# For simplicity, we'll use a subset of the training data as our test dataset\ntest_data = [\n    ['Red', 10, 'Apple'],\n    ['Purple', 1, 'Grape'],\n    ['Yellow', 8, 'Lemon']\n]\n\ndef calculate_accuracy(tree, test_data):\n    \"\"\"Calculate the accuracy of the decision tree on the test data.\"\"\"\n    correct_predictions = 0\n    for row in test_data:\n        prediction = predict(tree, row)\n        if prediction == row[-1]:\n            correct_predictions += 1\n    return correct_predictions / len(test_data)\n\n# Calculate the accuracy\naccuracy = calculate_accuracy(tree, test_data)\naccuracy",
      "outputs": []
    },
    {
      "id": "a51e2f53-2d55-4152-985d-b743b0f8281c",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "28bbdb61-264e-4255-98aa-5fc1a670923a",
          "cell_hidden": false
        },
        "ExecuteTime": {
          "end_time": "2023-10-10T17:09:29.861939+00:00",
          "start_time": "2023-10-10T17:09:29.704407+00:00"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        }
      },
      "execution_count": null,
      "source": "import random\n\n# Generate a larger dataset\nfruits = [\n    ['Red', 10, 'Apple'],\n    ['Purple', 1, 'Grape'],\n    ['Yellow', 8, 'Lemon'],\n    ['Red', 9, 'Apple'],\n    ['Purple', 1.5, 'Grape']\n]\n\nlarger_dataset = []\nfor _ in range(20):\n    larger_dataset.extend(fruits)\n\n# Shuffle the dataset\nrandom.shuffle(larger_dataset)\n\n# Split the dataset into 70% training and 30% testing\nsplit_index = int(0.7 * len(larger_dataset))\ntraining_data_larger = larger_dataset[:split_index]\ntest_data_larger = larger_dataset[split_index:]\n\nlen(training_data_larger), len(test_data_larger)",
      "outputs": []
    },
    {
      "id": "efa6d8a3-b43e-4f76-b0df-4cec01685c77",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "bf06fea3-f572-45c4-a020-6639d9989e06",
          "cell_hidden": false
        },
        "ExecuteTime": {
          "end_time": "2023-10-10T17:10:31.231050+00:00",
          "start_time": "2023-10-10T17:10:31.074424+00:00"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        }
      },
      "execution_count": null,
      "source": "# Build the decision tree using the larger training data\ntree_larger = build_tree(training_data_larger)\n\n# Calculate the accuracy on the test data\naccuracy_larger = calculate_accuracy(tree_larger, test_data_larger)\naccuracy_larger",
      "outputs": []
    },
    {
      "id": "1a951352-f172-4634-8d85-ae8e4558ff02",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "51d5f3f6-c3d5-4cc5-b503-f5dbc725a740",
          "cell_hidden": false
        },
        "ExecuteTime": {
          "end_time": "2023-10-10T17:12:04.821151+00:00",
          "start_time": "2023-10-10T17:12:04.664148+00:00"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        }
      },
      "execution_count": null,
      "source": "def print_tree(node, spacing=\"\"):\n    \"\"\"Print the decision tree in a textual format.\"\"\"\n    # Base case: we've reached a leaf\n    if node.prediction is not None:\n        print(spacing + \"Predict\", node.prediction)\n        return\n\n    # Print the question at this node\n    if isinstance(node.value, str):\n        question = f\"Is {node.feature} == {node.value}?\"\n    else:\n        question = f\"Is {node.feature} >= {node.value}?\"\n    print(spacing + question)\n\n    # Call this function recursively on the true branch\n    print(spacing + '--> True:')\n    print_tree(node.true_branch, spacing + \"  \")\n\n    # Call this function recursively on the false branch\n    print(spacing + '--> False:')\n    print_tree(node.false_branch, spacing + \"  \")\n\n# Print the tree\nprint_tree(tree_larger)",
      "outputs": []
    },
    {
      "id": "b5e4170b-4404-42ad-ad95-4e4e70c0e915",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "cdcb26f7-008f-499a-81bc-4e24e3804782",
          "cell_hidden": false
        },
        "ExecuteTime": {
          "end_time": "2023-10-10T17:13:47.763935+00:00",
          "start_time": "2023-10-10T17:13:47.604164+00:00"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        }
      },
      "execution_count": null,
      "source": "def tree_to_dot(node, dot_list=None, parent_name=None, decision=None):\n    \"\"\"Convert the decision tree to DOT format.\"\"\"\n    if dot_list is None:\n        dot_list = ['digraph Tree {']\n\n    # Base case: leaf node\n    if node.prediction is not None:\n        leaf_name = f'\"Leaf: {node.prediction}\"'\n        dot_list.append(f'{parent_name} -> {leaf_name} [label=\"{decision}\"];')\n        return dot_list\n\n    # Decision node\n    if isinstance(node.value, str):\n        node_name = f'\"{node.feature} == {node.value}?\"'\n    else:\n        node_name = f'\"{node.feature} >= {node.value}?\"'\n    if parent_name is not None and decision is not None:\n        dot_list.append(f'{parent_name} -> {node_name} [label=\"{decision}\"];')\n\n    # Recursively process true and false branches\n    tree_to_dot(node.true_branch, dot_list, node_name, 'True')\n    tree_to_dot(node.false_branch, dot_list, node_name, 'False')\n\n    return dot_list\n\n# Convert the tree to DOT format\ndot_representation = '\\n'.join(tree_to_dot(tree_larger)) + '\\n}'\ndot_representation",
      "outputs": []
    },
    {
      "id": "cd7d083f-d8a2-4f25-9747-4b1345e4f005",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "16cf214d-0d21-44a5-b49d-6449e021555f",
          "cell_hidden": false
        },
        "ExecuteTime": {
          "end_time": "2023-10-10T17:14:54.036271+00:00",
          "start_time": "2023-10-10T17:14:51.287790+00:00"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        }
      },
      "execution_count": null,
      "source": "!pip install -q graphviz",
      "outputs": []
    },
    {
      "id": "8d7f2967-7f8b-44c2-b178-381177d1cb58",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "31fcb87c-6a38-49c3-b62e-34a888994707",
          "cell_hidden": false
        },
        "ExecuteTime": {
          "end_time": "2023-10-10T17:15:36.572216+00:00",
          "start_time": "2023-10-10T17:15:36.374025+00:00"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        }
      },
      "execution_count": null,
      "source": "from graphviz import Digraph\n\ndef visualize_tree(node, dot=None):\n    \"\"\"Visualize the decision tree using Graphviz.\"\"\"\n    if dot is None:\n        dot = Digraph()\n\n    # Base case: leaf node\n    if node.prediction is not None:\n        leaf_name = f'Leaf: {node.prediction}'\n        dot.node(leaf_name, leaf_name, shape='ellipse', color='lightgreen')\n        return dot, leaf_name\n\n    # Decision node\n    if isinstance(node.value, str):\n        node_name = f'{node.feature} == {node.value}?'\n    else:\n        node_name = f'{node.feature} >= {node.value}?'\n    dot.node(node_name, node_name, shape='box')\n\n    # Recursively process true and false branches\n    dot, true_name = visualize_tree(node.true_branch, dot)\n    dot, false_name = visualize_tree(node.false_branch, dot)\n    dot.edge(node_name, true_name, label='True')\n    dot.edge(node_name, false_name, label='False')\n\n    return dot, node_name\n\n# Visualize the tree\ndot, _ = visualize_tree(tree_larger)\ndot",
      "outputs": []
    },
    {
      "id": "dbc71211-ceae-410e-8d40-f685e1582071",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "65f46269-f885-4f7e-960c-14981235093b",
          "cell_hidden": false
        },
        "ExecuteTime": {
          "end_time": "2023-10-10T17:16:58.570777+00:00",
          "start_time": "2023-10-10T17:16:58.409841+00:00"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        }
      },
      "execution_count": null,
      "source": "def visualize_tree_fixed(node, dot=None, parent_name=None, decision=None):\n    \"\"\"Visualize the decision tree using Graphviz with fixed node names.\"\"\"\n    if dot is None:\n        dot = Digraph()\n\n    # Generate unique node names based on the object id\n    node_name = str(id(node))\n\n    # Base case: leaf node\n    if node.prediction is not None:\n        label = f'Leaf: {node.prediction}'\n        dot.node(node_name, label, shape='ellipse', color='lightgreen')\n    else:\n        # Decision node\n        if isinstance(node.value, str):\n            label = f'{node.feature} == {node.value}?'\n        else:\n            label = f'{node.feature} >= {node.value}?'\n        dot.node(node_name, label, shape='box')\n\n        # Recursively process true and false branches\n        true_name = visualize_tree_fixed(node.true_branch, dot, node_name, 'True')\n        false_name = visualize_tree_fixed(node.false_branch, dot, node_name, 'False')\n        dot.edge(node_name, true_name, label='True')\n        dot.edge(node_name, false_name, label='False')\n\n    return node_name\n\n# Visualize the tree with fixed node names\nvisualize_tree_fixed(tree_larger, dot=Digraph())",
      "outputs": []
    }
  ]
}