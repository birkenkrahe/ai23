<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>What is AI?</title>
<meta name="author" content="Marcus Birkenkrahe"/>
<meta name="description" content=""/>
<meta name="keywords" content=""/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.css"/>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/theme/black.css" id="theme"/>

</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide"><h1 class="title">What is AI?</h1><p class="subtitle">Seminar on Artificial Intelligence Fall 2023</p>
<h2 class="author">Marcus Birkenkrahe</h2><p class="date">Created: 2023-08-29 Tue 22:49</p>
</section>
<section>
<section id="slide-org2270478">
<h2 id="org2270478">What're you going to learn?</h2>
<ul>
<li>What is intelligence?</li>
<li>Different approaches to AI</li>
<li>The standard model of AI</li>
<li>Bounded rationality</li>
<li>The Value alignment problem</li>
<li>Asimov's Robot Laws</li>
<li>What's next?</li>

</ul>

</section>
</section>
<section>
<section id="slide-org711d5fe">
<h2 id="org711d5fe">What is intelligence?</h2>

<div id="orgf763189" class="figure">
<p><img src="../img/intelligence.gif" alt="intelligence.gif" height="500px" />
</p>
</div>

</section>
<section id="slide-org3f0c20e">
<h3 id="org3f0c20e">Search patterns</h3>

<div id="org341f11c" class="figure">
<p><img src="../img/googletrends23.png" alt="googletrends23.png" width="700px" />
</p>
</div>

</section>
<section id="slide-orgeab001b">
<h3 id="orgeab001b">Group work</h3>

<div id="org187bb47" class="figure">
<p><img src="../img/groupwork.gif" alt="groupwork.gif" height="200px" />
</p>
</div>

<ul>
<li>Get together in groups of 2-3</li>
<li>Define INTELLIGENCE (5')</li>
<li>Define ARTIFICIAL INTELLIGENCE (5')</li>
<li>Briefly present your results (10')</li>

</ul>

</section>
<section id="slide-org29ceecb">
<h3 id="org29ceecb">AI's view</h3>

<div id="org71dec8f" class="figure">
<p><img src="../img/chatgpt.jpeg" alt="chatgpt.jpeg" width="700px" />
</p>
</div>

<p>
Is there something about human intelligence that is specifically
human and not shared by machines or other non-human beings?
</p>

<pre class="example" id="orgfe94196">
"While AI has made significant strides in replicating specific tasks
that were once the domain of human intelligence, there remain several
aspects that are uniquely human and are far from being fully
understood or replicated by machines." (ChatGPT)
</pre>
<aside class="notes">
<p>
Source:  <a href="https://shareg.pt/xk8YkuO">ChatGPT</a>
</p>

<p>
Highlighted specifically human intelligences: Emotional intelligence,
Creativity, Contextual Understanding, Generalization and Transfer
Learning, Self-awareness and Consciousness, Moral and Ethical
Reasoning, Social Intelligence.
</p>

<p>
Image: produced with Dall-E by OpenAI with the prompt "Give me a
portrait of ChatGPT in three different styles - as an 18th century
drawing, as a Renaissance painting, and as a graphics image.
</p>

</aside>

</section>
</section>
<section>
<section id="slide-org8bbb6b6">
<h2 id="org8bbb6b6">Different approaches to AI</h2>

<div id="org03d9519" class="figure">
<p><img src="../img/approach.gif" alt="approach.gif" height="300px" />
</p>
</div>

<p>
Which fields of inquiry (= disciplines) to use?
</p>

</section>
<section id="slide-orgc94f53a">
<h3 id="orgc94f53a">Fields of systematic inquiry</h3>

<div id="org41eff31" class="figure">
<p><img src="../img/fields.gif" alt="fields.gif" height="200px" />
</p>
</div>

<ul>
<li>Language</li>
<li>Philosophy</li>
<li>Science</li>
<li>History</li>

</ul>

</section>
<section id="slide-org8974b26">
<h3 id="org8974b26">Fundamental questions</h3>

<div id="orgf56286a" class="figure">
<p><img src="../img/humanmachine.jpg" alt="humanmachine.jpg" width="500px" />
</p>
</div>

<ul>
<li>Should we focus on humans?</li>
<li>Should we focus on machines?</li>

</ul>

</section>
<section id="slide-orgb77bb4e">
<h3 id="orgb77bb4e">Four approaches</h3>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">BEHAVIOR / ACTION</th>
<th scope="col" class="org-left">THOUGHT / LOGIC</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">HUMAN</td>
<td class="org-left">Turing Test</td>
<td class="org-left">Cognitive modeling</td>
</tr>

<tr>
<td class="org-left">RATIONALITY</td>
<td class="org-left">Rational Agents</td>
<td class="org-left">Laws of Thought</td>
</tr>
</tbody>
</table>

<aside class="notes">
<p>
Like human vs. non-human and body vs. soul.
</p>

<p>
Problems with this categorisation:
</p>
<ol>
<li>the axes are not independent of one another - rationality
('reasoning') is linked to thought;</li>
<li>Behaviour and thought are not independent from another.</li>

</ol>

</aside>

</section>
<section id="slide-org919d05d">
<h4 id="org919d05d">Four scenarios</h4>

<div id="org070aca8" class="figure">
<p><img src="../img/approaches1.png" alt="approaches1.png" height="500px" />
</p>
</div>

</section>
<section id="slide-org6fda151">
<h4 id="org6fda151">Acting humanly ("Turing test" approach)</h4>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">Natural language processing</td>
</tr>

<tr>
<td class="org-left">Knowledge representation</td>
</tr>

<tr>
<td class="org-left">Automated reasoning</td>
</tr>

<tr>
<td class="org-left">Machine learning</td>
</tr>

<tr>
<td class="org-left">Computer vision</td>
</tr>

<tr>
<td class="org-left">Robotics</td>
</tr>
</tbody>
</table>

<aside class="notes">
<p>
Turing (1950) Can a machine think? Test: if a human cannot tell the
machine from a human (<a href="https://youtu.be/Umc9ezAyJv0?si=lNemHMH2A3uYEhST">Voight-Kampff Test, Blade Runner</a>).
</p>

<p>
Six disciplines dominate AI research today. Emphasis shifted away from
the Turing test - "aeronautical engineers do not define the goal of
their field as making 'machines that fly so exactly like pigeons that
they can fool even other pigeons'". Except: flight is not intelligence.
</p>

</aside>

</section>
<section id="slide-orgdb29c4f">
<h4 id="orgdb29c4f">Thinking humanly ("cognitive modeling" approach)</h4>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">Introspection</td>
</tr>

<tr>
<td class="org-left">Psychological experiments</td>
</tr>

<tr>
<td class="org-left">Brain imaging</td>
</tr>

<tr>
<td class="org-left">Cognitive science</td>
</tr>

<tr>
<td class="org-left">Algorithms</td>
</tr>
</tbody>
</table>

<aside class="notes">
<p>
Goal: establish a theory of mind. Newell and Simon ("The sciences of
the artificial", 1955), Nobel Prize Economics, designed a General
Problem Solver that solves problems like a human (cognitively).
</p>

<p>
The two fields have since separated - machine cognition is not human
cognition.
</p>

</aside>

</section>
<section id="slide-orge72c755">
<h4 id="orge72c755">Thinking rationally ("laws of thought" approach)</h4>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">Syllogistic reasoning</td>
</tr>

<tr>
<td class="org-left">Logic</td>
</tr>

<tr>
<td class="org-left">Expert systems</td>
</tr>

<tr>
<td class="org-left">Uncertainty</td>
</tr>

<tr>
<td class="org-left">Probability</td>
</tr>
</tbody>
</table>

<aside class="notes">
<p>
Syllogistic reasoning: 1. Humans think. 2. The machine
thinks. 3. Therefore the machine is human.
</p>

<p>
Logic via its rules provides certainty. The real world is uncertain -
we don't know the complete set of rules (expert systems).
</p>

<p>
Probability (computing chances based on samples) fills this gap:
machine learning algorithms combine rigorous reasoning with uncertain
data. Emphasis is now on the data.
</p>

</aside>

</section>
<section id="slide-org1ac2d90">
<h4 id="org1ac2d90">Acting rationally ("rational agent" approach)</h4>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">Combination approach</td>
</tr>

<tr>
<td class="org-left">Constructivist</td>
</tr>

<tr>
<td class="org-left">Doing the right thing</td>
</tr>

<tr>
<td class="org-left">Standard model</td>
</tr>

<tr>
<td class="org-left">Control theory</td>
</tr>
</tbody>
</table>

<aside class="notes">
<p>
Advantages of this approach:
</p>
<ol>
<li>more general than 'Laws of thought'/rational thinking because
logical inference is only one way of achieving rationality (which
others are there? E.g. heuristics based on recognized patterns).</li>
<li>the standard of rationality is mathematically well-defined so that
we can often work back from a mathematical law to a specific agent
design. E.g. Rumba robots, which use topology in their algorithms.</li>

</ol>

</aside>

</section>
<section id="slide-org6fa9373">
<h3 id="org6fa9373">Major issues</h3>

<div id="org38af1b7" class="figure">
<p><img src="../img/issues.gif" alt="issues.gif" height="200px" />
</p>
</div>

<ul>
<li>Bounded Rationality</li>
<li>Value alignment problem</li>

</ul>

</section>
<section id="slide-orgf44900c">
<h3 id="orgf44900c">Bounded rationality</h3>

<div id="org7133fdb" class="figure">
<p><img src="../img/bakopoulos.png" alt="bakopoulos.png" width="300px" />
</p>
</div>

<p>
Image: <a href="https://aisel.aisnet.org/icis1985/4/">Bakopoulos, 1985</a>
</p>

<blockquote >
<p>
AIMA: "For perfect rationality, the computational demands are just
too high."
</p>
</blockquote>

<aside class="notes">
<p>
HOME READING ASSIGNMENT - 6 pages. (<a href="https://shareg.pt/MzzqdF0">ChatGPT summary.</a>)
</p>

<p>
The article by Bakopoulos helped to move IT from an arcane
discipline for technologists and nerds to a mainstream service
industry. To do this, Bakopoulos capitalized on the notion that
humans are not perfectly rational, that their rationality is
bounded by their humanity: "Data has no value unless put in the
context of the appropriate models, a process taxing the human
capacities to communicate, memorize and process information, and
thus leading to <i>bounded rationality</i>, which is a central concept
in organizational behavior theory."
</p>

<p>
I worked through this article a while back for a lecture I was
preparing, and found it remarkably difficult for such an old paper,
with a lot of connections in different directions - technology,
business, information theory, and philosophy.
</p>

<p>
Bakopoulos' result that information systems have no (or only
little) value without being properly integrated into business, and
that IT is useless if it does not 'speak" to people in ways that
they can understand and with results that they can measure, is
wonderfully relevant for the future development of AI, too.
</p>

</aside>

</section>
<section id="slide-org361d42a">
<h3 id="org361d42a">Value alignment</h3>

<div id="org6b8875b" class="figure">
<p><img src="../img/mechanicalturk.png" alt="mechanicalturk.png" width="200px" />
</p>
</div>

<p>
Image: <a href="https://www.amazon.com/Turk-Famous-Eighteenth-Century-Chess-Playing-Machine/dp/B000HWZ28Q">The Mechanical Turk</a>
</p>

<blockquote >
<p>
AIMA: "The values or objectives put into the machine must be
aligned with those of the human."
</p>
</blockquote>

<aside class="notes">
<p>
This kind of "alignment" sounds like an engineering task, but
actually it is a lot more complicated (or actually complex in a
technical sense): if rational agents are supposed to "do the right
thing", then their actions have to be not just logical, but
appropriate and moral. There is no algorithm for that - both
appropriateness (e.g. to a situation) and morality depend on the
circumstances. Take the example of Grace, the "ultra-lifelike
robotic nurse" from Hanson Robotics: she was designed for a certain
set of circumstances and both by, and for a particular set of moral
values. Will she do equally well in Japan and in Belgium, the
country with the "<a href="https://www.pbs.org/newshour/show/right-die-belgium-inside-worlds-liberal-euthanasia-laws">world's most liberal euthanasia law</a>", and
therefore possibly a different approach to caring for the elderly?
</p>

<p>
The example of an 'unethical rational agent' chosen by AIMA, which
relates to the "Mechanical Turk", a chess machine that was operated
by a human hidden inside the machine, is admittedly a lot less
critical than when taking care of the sick and elderly is at
stake. However, the age of AI that dazzled us by beating chess
champions is long behind us, and the age of robots like Grace is
upon us!
</p>

</aside>

</section>
<section id="slide-org46500b9">
<h3 id="org46500b9">Pros and cons</h3>

<div id="org2669d32" class="figure">
<p><img src="../img/groupwork.gif" alt="groupwork.gif" height="200px" />
</p>
</div>

<ul>
<li>Get together in groups of 2-3</li>
<li>Each group covers one approach</li>
<li>List pros and cons of your approach</li>
<li>Put your results <a href="https://ideaboardz.com/for/AI%20approaches%20pros%20&amp;amp;%20cons/4063343">on the Kanban board</a></li>

</ul>

</section>
</section>
<section>
<section id="slide-org743f895">
<h2 id="org743f895"><a href="https://en.wikipedia.org/wiki/Three_Laws_of_Robotics">Asimov's robot laws</a></h2>

<div id="orgc0dd1cc" class="figure">
<p><img src="../img/asimov.jpg" alt="asimov.jpg" height="400px" />
</p>
</div>

<p>
Image: cover of "I, Robot" by Isaac Asimov (1940)
</p>

</section>
<section id="slide-org14ab219">
<h3 id="org14ab219">Which approach fits these laws best?</h3>
<ol>
<li>A robot may not injure a human being or, through inaction, allow
a human being to come to harm.</li>
<li>A robot must obey the orders given it by human beings except
where such orders would conflict with the First Law.</li>
<li>A robot must protect its own existence as long as such
protection does not conflict with the First or Second Law.</li>

</ol>

</section>
<section id="slide-orgaa77b3d">
<h3 id="orgaa77b3d">Russell's AI Principles (Asimov 2.0)</h3>
<ol>
<li>The machine's only objective is to maximis the realisation of human
preferences.</li>
<li>The machine is initially uncertain about what those preferences
are.</li>
<li>The ultimate source of information about human preferences is human
behaviour.</li>

</ol>

<aside class="notes">
<p>
Source: Eve Poole, Robot Souls, Routledge 2023.
</p>

<p>
Russell is Vice Chair of the World Economic Forum's Council on AI and
Robotics - strict controls of AI especially for warfare. AI must only
ever be instrumentally beneficial to humans and should attach no
intrinsic value to its own well-being or existence.
</p>

<ol>
<li>In any conflict of programming, human interests must prevail.</li>
<li>Protect (1) by not making the AI too certain of itself</li>
<li>Further risk mitigation: must observe human behaviour.</li>

</ol>

</aside>

</section>
<section id="slide-org58507f1">
<h3 id="org58507f1">Pasquale's Laws</h3>
<ol>
<li>Robotic systems and AI should complement professionals, not replace
them.</li>
<li>Robotic systems and AI should not counterfeit humanity.</li>
<li>Robotic systems and AI should not intensify zero-sum arms races.</li>
<li>Robotic systems and AI must always indicate the identity of their
creator(s), controller(s), and owner(s).</li>

</ol>

<aside class="notes">
<p>
Frank Pasquale is a expert on AI law, professor at Brooklyn Law
School, on the US Natinal AI Advisory Committee.
</p>

</aside>

</section>
</section>
<section>
<section id="slide-org374609e">
<h2 id="org374609e">What's next?</h2>

<div id="org1f42518" class="figure">
<p><img src="../img/river.gif" alt="river.gif" height="300px" />
</p>
</div>

<ul>
<li>Scientific foundations of AI</li>
<li>History of AI</li>

</ul>

</section>
</section>
<section>
<section id="slide-org2fc4b8f">
<h2 id="org2fc4b8f">Any questions?</h2>

<div id="org0143d36" class="figure">
<p><img src="../img/thankyou.gif" alt="thankyou.gif" height="400px" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-orgb611781">
<h2 id="orgb611781">References</h2>
<p>
Bakopoulos, J. Yannis, "Toward a More Precise Concept of Information
Technology" (1985). ICIS 1985 Proceedings. 4.
<a href="http://aisel.aisnet.org/icis1985/4">http://aisel.aisnet.org/icis1985/4</a>
</p>
</section>
</section>
</div>
</div>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/markdown/markdown.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/zoom/zoom.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/notes/notes.js"></script>


<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
plugins: [RevealMarkdown, RevealZoom, RevealNotes],
transition: 'cube'
});

</script>
</body>
</html>
